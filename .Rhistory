stringr::str_extract(".*(?=\\.txt$)")
text_filepaths=paste0(from_dir,"/",text_files)
textdata=tibble::tibble(id=text_ids,
text=text_filepaths %>%
purrr::map(readLines,
encoding=encoding) %>%
purrr::map_chr(stringr::str_flatten,
collapse=" "))
}
if(sourcetype=="rtibble"){
textdata=rtibble
}
if(!("id" %in% colnames(textdata))){
textdata=textdata %>%
dplyr::mutate(id=stringr::str_pad(1:dplyr::n(),
width=stringr::str_length(dplyr::n()),
pad="0")) %>%
dplyr::mutate(id=paste0("txt",.data$id))
}
textdata=textdata %>%
dplyr::select(.data$id,.data$text)
return(textdata)
}
devtools::document()
rm(get_textdata)
devtools::document()
library(textoteR)
devtools::document()
library(textoteR)
devtools::document()
library(textoteR)
Vignette(textoteR)
?browseVignettes
?browseVignettes("textoteR")
iramuteq_to_txm(from_dir=system.file("extdata",package="textoteR"),
filename="macron_covid.txt"
to_dir="macron_covid_corpus",)
devtools::document()
vignette("textoteR")
vignette("textoteR")
library(textoteR)
vignette(package="textoteR")
devtools::document()
library(textoteR)
vignette(package="textoteR")
devtools::build_vignettes()
vignette(package="textoteR")
library(textoteR)
vignette(package="textoteR")
vignette(package="textoteR")
library(textoteR)
vignette(package="textoteR")
devtools::install(build_vignettes=TRUE)
vignette(package="textoteR")
devtools::install(build_vignettes=TRUE)
remove.packages("textoteR")
remotes::install_github("lvaudor/textoteR")
vignette("textoteR")
library(textoteR)
vignette("textoteR")
remotes::install_github("lvaudor/textoteR", build_vignettes=TRUE)
remotes::install_github("lvaudor/textoteR", build_vignettes=TRUE, force=TRUE)
vignette("textoteR")
library(textoteR)
vignette("textoteR")
library(textoteR)
vignette("textoteR")
remotes::install_github("lvaudor/textoteR", build_vignettes=TRUE, force=TRUE)
library(textoteR)
vignette("textoteR")
install.packages("tidyverse")
sort(c("cc","aa"))
sort(c("1c","2aa","2d"))
get_textdata
no_jekyll
#' txm_to_iramuteq(from_dir=system.file("extdata/fables",
#'                                      package="textoteR"),
#'                 filename="alltexts_iramuteq.txt")
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="alltexts_iramuteq.txt")
library(textoteR)
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="alltexts_iramuteq.txt")
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="alltexts_iramuteq.txt")
txm_to_iramutew
from_dir=system.file("extdata/fables",
#'                                      package="textoteR")
filename="alltexts_iramuteq.txt"
from_dir=system.file("extdata/fables")
filename="alltexts_iramuteq.txt"
to_dir="NULL"
encoding="UTF-8"
metadata=get_metadata(sourcetype="txm",
from_dir=from_dir,
encoding=encoding) %>%
format_metadata() %>%
dplyr::arrange(id)
textdata=get_textdata(sourcetype="txm",
from_dir=from_dir,
encoding=encoding)
dplyr::arrange(id)
usethis::use_pkgdown_github_pages()
usethis::use_pgithub_pages()
usethis::use_github_pages()
filename="data-raw/alltexts_iramuteq.txt")
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="data-raw/alltexts_iramuteq.txt")
pkgdown::build_site_github_pages()
pkgdown::preview_page('reference/write_to_txm.html')
pkgdown::preview_page('reference/write_to_txm.html')
pkgdown::build_site_github_pages()
replace_with_nothing("This is an example xxxx of unclean text https://example.com",
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")")))
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")))
replace_with_nothing("This is an example xxxx of unclean text https://example.com",
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")))
replace_with_nothing("This is an example xxxx of unclean text https://example.com",
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")))
replace_with_nothing("This is an example xxxx of unclean text https://example.com",
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")))
data.frame(from=c("xxxx","(?<=https:\\/\\/)\\w*")))
replace_with_nothing("This is an example xxxx of unclean texxxxt brrr.",
data.frame(from=c("xxxx","brrr")))
replace_with_nothing("This is an example xxxx of unclean texxxxt brrr.",
data.frame(from=c("xxxx","brrr")))
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
data.frame(from=c("xxx","brrr")))
#' Cleans some patterns in a text by removing them
#'
#' @param text the corpus directory (contains metadata.csv and multiple .txt files)
#' @param patterns_to_nothing the table with the patterns to replace (in column "from")
#' @return the same text with patterns replaced by nothing
#' @export
#'
#' @examples
#' replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
#'                       data.frame(from=c("xxx","brrr")))
replace_with_nothing=function(text, patterns_to_nothing){
for (i in 1:nrow(patterns_to_nothing)){
text=stringr::str_replace_all(text,patterns_to_nothing$from[i],"")
}
return(text)
}
dim(patterns_to_nothing)
dim(patterns_to_nothing
data.frame(from=c("xxx","brrr")) ->patterns_to_nothing
dim(patterns_to_nothing
)
truc=c(433,232)
dim(truc)
is.null(dim(patterns_to_nothing))
is.null(dim(truc))
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
rm(replace_with_nothing)
c("xxx","brrr"))
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
#' Cleans some patterns in a text by removing them
#'
#' @param text the corpus directory (contains metadata.csv and multiple .txt files)
#' @param patterns_to_nothing the table with the patterns to replace (in column "from")
#' @return the same text with patterns replaced by nothing
#' @export
#'
#' @examples
#' replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
#'                       c("xxx","brrr"))
replace_with_nothing=function(text, patterns_to_nothing){
if(is.null(dim(patterns_to_nothing))){
from=patterns_to_nothing$from}else{
from=patterns_to_nothing
}
for (i in 1:length(from)){
text=stringr::str_replace_all(text,from[i],"")
}
return(text)
}
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
#' Cleans some patterns in a text by removing them
#'
#' @param text the corpus directory (contains metadata.csv and multiple .txt files)
#' @param patterns_to_nothing the table with the patterns to replace (in column "from")
#' @return the same text with patterns replaced by nothing
#' @export
#'
#' @examples
#' replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
#'                       c("xxx","brrr"))
replace_with_nothing=function(text, patterns_to_nothing){
if(!is.null(dim(patterns_to_nothing))){
from=patterns_to_nothing$from}else{
from=patterns_to_nothing
}
for (i in 1:length(from)){
text=stringr::str_replace_all(text,from[i],"")
}
return(text)
}
replace_with_nothing("This is an example xxx of unclean texxxxt brrr.",
c("xxx","brrr"))
replace_with_nothing(c("This is an examplexxx of unclean texxxxt brrr.",
"brrrxxxx And anotherxxx one."),
c("xxx","brrr"))
c("xxx","brrr"))
replace_with_nothing(c("This is an examplexxx of unclean texxxxt brrr.",
"brrrxxxx And anotherxxx one.",
"Yet anotxxxer."),
c("xxx","brrr"))
replace_with_nothing(c("This is an examplexxx of unclean texxxxt brrr.",
"brrrxxxx And anotherxxx one.",
"Yet anothxxxer."),
c("xxx","brrr"))
replace_with(c("This is an apple and this is an orange.",
"Here is a banana and this is an apple"),
from=c("apple","orange"),to=c("pear","kiwi"))
rm(list=ls())
replace_with(c("This is an apple and this is an orange.",
"Here is a banana and this is an apple"),
from=c("apple","orange"),to=c("pear","kiwi"))
replace_with
library(textoteR)
replace_with
replace_with(c("This is an apple and this is an orange.",
"Here is a banana and this is an apple"),
from=c("apple","orange"),to=c("pear","kiwi"))
replace_with(c("This is an apple and this is an orange.",
"Here is a banana and this is an apple"),
from=c("apple","orange"),
to=c("pear","kiwi"))
patterns_to_strings=NULL
!is.null(dim(patterns_to_strings))
replace_with(c("This is an apple and this is an orange.",
"Here is a banana and this is an apple"),
from=c("apple","orange"),
to=c("pear","kiwi"))
#' replace_with(c("This is an apple and this is a banana.",
#'                "Here is a banana and and an apple"),
#'              from=c("apple","banana"),
#'              to=c("orange","kiwi"))
replace_with(c("This is an apple and this is a banana.",
"Here is a banana and and an apple"),
from=c("apple","banana"),
to=c("orange","kiwi"))
usethis::use_package("tidytext")
corpus_data=iramuteq_to_rtibble("data-raw/alltexts_iramuteq.txt")
corpus_data=iramuteq_to_rtibble(filename="data-raw/alltexts_iramuteq.txt")
?iramuteq_to_rtibble
corpus_data=iramuteq_to_rtibble(filename="data-raw/alltexts_iramuteq.txt")
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
unnest_words_keep_context(corpus_data,nwords=15)
dplyr::
unnest_words_keep_context(corpus_data,nwords=15)
corpus_data
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="data-raw/alltexts_iramuteq.txt")
?txm_to_iramuteq
package="textoteR"),
filename="data-raw/alltexts_iramuteq.txt")
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="data-raw/alltexts_iramuteq.txt")
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
corpus_data
from_dir="data-raw"
filename="alltexts_iramuteq.txt"
metadata=get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
metadata
textdata=get_textdata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
encoding
encoding="UTF-8"
textdata=get_textdata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
textdata
rtibble=dplyr::left_join(metadata,
textdata,
by="id")
rtibble
get_textdata
sourcetype="iramuteq"
if(!dir.exists(from_dir)){stop("Directory from_dir does not exist")}
filename=paste0(from_dir,"/",filename)
if(!file.exists(filename)){stop("filename does not correspond to existing file")}
textot=readLines(filename)
textot=textot[textot!=""]
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
library(tidyverse)
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
textdata
!("id" %in% colnames(textdata))
textdata %>%
dplyr::mutate(id=stringr::str_pad(1:dplyr::n(),
width=stringr::str_length(dplyr::n()),
pad="0")) %>%
dplyr::mutate(id=paste0("txt",.data$id))
get_textdata(sourcetype="txm",
from_dir=system.file("extdata/fables",package="textoteR"),
encoding="UTF-8")
get_textdata(sourcetype="iramuteq",
from_dir=system.file("extdata",package="textoteR"),
filename="macron_covid.txt",
encoding="UTF-8")
get_metadata(textot)
textot=readLines(filename)
textot=textot[textot!=""]
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
?get_metadata
get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
filename
from_dir="data-raw"é
from_dir="data-raw"
filename="alltexts_iramuteq.txt"
get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
textdata=bind_cols(textdata,metadata %>% dplyr::select(id))
textdata
textdata=textdata %>%
dplyr::select(.data$id,.data$text)
textdata=textdata %>%
dplyr::select(id,text)
textdata
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
txm_to_iramuteq(from_dir=system.file("extdata/fables",
package="textoteR"),
filename="data-raw/alltexts_iramuteq.txt")
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
from_dir="data-raw"
filename="alltexts_iramuteq.txt"
metadata=get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
textdata=get_textdata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
from_dir
filename
filename=paste0(from_dir,"/",filename)
file.exists(filename)
!file.exists(filename)
textot=readLines(filename)
textot=textot[textot!=""]
metadata=textot %>%
stringr::str_subset("\\*{4}") %>%
stringr::str_replace("\\*{4}\\s","") %>%
stringr::str_replace("^\\*","") %>%
stringr::str_split("\\s\\*")
varnames= metadata %>%
purrr::map(stringr::str_replace,
pattern="_[^_]*$",
replacement="") %>%
purrr::pluck(1)
metadata= metadata  %>%
purrr::map(stringr::str_extract,
pattern="[^_]*$") %>%
purrr::map(t) %>%
purrr::map_df(as.data.frame) %>%
purrr::set_names(varnames) %>%
tibble::as_tibble(.name_repair="minimal")
!("id" %in% colnames(metadata))
get_metadata(sourcetype="iramuteq",
from_dir=system.file("extdata",package="textoteR"),
filename="macron_covid.txt",
encoding="UTF-8")
from_dir
filename
filename="alltexts_iramuteq.txt"
textdata=get_textdata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
if(all(c("iramuteq","txm","rtibble")!=sourcetype)){
stop("Argument sourcetype must be one of 'iramuteq','txm' or 'rtibble'")
}
if(sourcetype=="iramuteq"){
if(!dir.exists(from_dir)){stop("Directory from_dir does not exist")}
filename=paste0(from_dir,"/",filename)
if(!file.exists(filename)){stop("filename does not correspond to existing file")}
textot=readLines(filename)
textot=textot[textot!=""]
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
# need to associate text to id going through metadata
get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
textdata=bind_cols(textdata, metadata %>% dplyr::select(id))
}
filename
filename="alltexts_iramuteq.txt"
if(!dir.exists(from_dir)){stop("Directory from_dir does not exist")}
filename=paste0(from_dir,"/",filename)
if(!file.exists(filename)){stop("filename does not correspond to existing file")}
textot=readLines(filename)
textot=textot[textot!=""]
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
# need to associate text to id going through metadata
get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
filename
filename="alltexts_iramuteq.txt"
if(all(c("iramuteq","txm","rtibble")!=sourcetype)){
stop("Argument sourcetype must be one of 'iramuteq','txm' or 'rtibble'")
}
if(sourcetype=="iramuteq"){
if(!dir.exists(from_dir)){stop("Directory from_dir does not exist")}
cfilename=paste0(from_dir,"/",filename)
if(!file.exists(cfilename)){stop("filename does not correspond to existing file")}
textot=readLines(cfilename)
textot=textot[textot!=""]
textdata= textot %>%
stringr::str_subset("\\*{4}", negate=TRUE) %>%
tibble::tibble(text=.)
# need to associate text to id going through metadata
get_metadata(sourcetype="iramuteq",
from_dir=from_dir,
filename=filename,
encoding=encoding)
textdata=bind_cols(textdata, metadata %>% dplyr::select(id))
}
if(sourcetype=="txm"){
if(!dir.exists(from_dir)){stop("Directory from_dir does not exist")}
text_files=list.files(from_dir) %>%
stringr::str_subset("\\.txt$")
text_ids=text_files %>%
stringr::str_extract(".*(?=\\.txt$)")
text_filepaths=paste0(from_dir,"/",text_files)
textdata=tibble::tibble(id=text_ids,
text=text_filepaths %>%
purrr::map(readLines,
encoding=encoding) %>%
purrr::map_chr(stringr::str_flatten,
collapse=" "))
}
textdata
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
unnest_words_keep_context(corpus_data,nwords=15)
corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
unnest_words_keep_context(corpus_data,input="text",nwords=15)
#'
#' @param data data to tokenize (as provided to tidytext::unnest_tokens)
#' @param input the column of the data that contains the text to be tokenized
#' @param nwords the number of words that constitute a segment
#' @return the tokenized data with a segment column as word context.
#' @export
#'
#' @examples
#' corpus_data=iramuteq_to_rtibble(from_dir="data-raw",filename="alltexts_iramuteq.txt")
#' unnest_words_keep_context(corpus_data,input="text",nwords=15)
unnest_words_keep_context=function(data,
input,
nwords=20){
segments=tidytext::unnest_tokens(data,
input=input,
output="segment",
token="ngrams",
n=nwords) %>%
dplyr::mutate(ns=(1:dplyr::n())-1)
lemma_data=tidytext::unnest_tokens(segments,
input=segment,
output="word",
token="words",
drop=FALSE) %>%
dplyr::group_by(ns) %>%
dplyr::mutate(n=1:dplyr::n(),
l=ns+n) %>%
dplyr::ungroup() %>%
dplyr::group_by(l,word) %>%
dplyr::mutate(central=ns[which.min(abs(10-nwords))]) %>%
dplyr::ungroup() %>%
dplyr::filter(ns==central) %>%
dplyr::select(-n,-l,-ns,-central)
return(lemma_data)
}
